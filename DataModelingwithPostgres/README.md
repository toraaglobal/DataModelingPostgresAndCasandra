# Data Modeling with Postgres
### Project Description
This project create a database for Sparkily in postgres.Sparkily wants to analyze the data they have been collecting on songs and user activity on their music streaming app.
The analytics team is particularly interested in understanding what songs user are listening to.Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

### Datasets
Sparkily has two different source of data that is integrated as described below:
1. Song dataset :  Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID. For example, here are filepaths to two files in this dataset.
```
song_data/A/B/C/TRABCEI128F424C983.json
song_data/A/A/B/TRAABJL12903CDCF1A.json
```

And below is an example of what a single song file, TRAABJL12903CDCF1A.json, looks like.

```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```


1. log dataset : The second dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

The log files in the dataset you'll be working with are partitioned by year and month. For example, here are filepaths to two files in this dataset.

```
log_data/2018/11/2018-11-12-events.json
log_data/2018/11/2018-11-13-events.json
```

### Initial Setup
Clone the repo using the commad `git clone https://github.com/toraaglobal/DataModelingPostgresAndCasandra.git` 

Navigate to the project root directory `cd DataModelingPostgresAndCasandra/DataModelingwithPostgres`

Run the `create_tables.py` to initialize the database and create all the tables using the command below:
```
python create_tables.py
```

Run the `etl` script to migrate the data from the file system to populate the database

### Schema of the table created in the posgres database
![Schema](https://github.com/toraaglobal/DataModelingPostgresAndCasandra/blob/master/songplayschema.jpg)

### Purpose of the database
The database can now be use by the analytics team to understand the users listening to certain music at a particular time.
Example query is shown below.

```
SELECT t1.user_agent,t2.firstname, t2.last_name, t3.title, t3.duration,t4.name as artist_name
from songplays t1 join users t2 on t1.user_id=t2.user_id
join songs t3 on t3.song_id = t1.song_id
join artist t4 on t4.artist_id = t1.artist_id
```